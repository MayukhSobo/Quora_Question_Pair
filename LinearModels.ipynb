{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect('dataset/Cleaned.db') as conn:\n",
    "    train = pd.read_sql_query('SELECT * FROM train', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_grid(grid):\n",
    "    parms = list(grid.param_grid.keys())\n",
    "    columns = ['Iter #']\n",
    "    scorings = grid.scoring\n",
    "    for scoring in scorings:\n",
    "        for typ in ['train', 'test']:\n",
    "            columns.append(f'{typ}_{scoring}')\n",
    "    columns.extend(['fit_time', 'score_time'])\n",
    "    for param in grid.param_grid.keys():\n",
    "        columns.append(param)\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    cv_res = grid.cv_results_\n",
    "    for col in columns[1:-len(parms)]:\n",
    "        df[col] = cv_res['mean_' + col]\n",
    "    items = 1\n",
    "    for k, v in grid.param_grid.items():\n",
    "        items *= len(v)\n",
    "    df['Iter #'] = np.array(range(items)) + 1\n",
    "    res = defaultdict(list)\n",
    "    for each in grid.cv_results_['params']:\n",
    "        for p in parms:\n",
    "            res[p].append(each[p])\n",
    "    for k, v in res.items():\n",
    "        df[k] = v\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404289, 46)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)  # Sorry to drop nans but code was failing with fillna\n",
    "# later try with imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train.is_duplicate\n",
    "y_true = list(map(int, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop([\n",
    "    'id',\n",
    "    'qid1',\n",
    "    'qid2',\n",
    "    'is_duplicate'\n",
    "], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(train, y_true, stratify=y_true, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281967, 42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120843, 42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit(Xtrain.question1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_train_vec = tfidf.transform(Xtrain.question1)\n",
    "q1_test_vec = tfidf.transform(Xtest.question1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281967, 48696)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit(Xtrain.question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_train_vec = tfidf.transform(Xtrain.question2)\n",
    "q2_test_vec = tfidf.transform(Xtest.question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281967, 44357)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "Xtrain.drop(['question1', 'question2'], axis=1, inplace=True)\n",
    "Xtest.drop(['question1', 'question2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(q1_train_vec.shape[0] == Xtrain.shape[0])\n",
    "assert(q2_train_vec.shape[0] == Xtrain.shape[0])\n",
    "assert(q1_test_vec.shape[0] == Xtest.shape[0])\n",
    "assert(q2_test_vec.shape[0] == Xtest.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = hstack((q1_train_vec, q2_train_vec, np.array(Xtrain)))\n",
    "assert(X_train.shape[1] == q1_train_vec.shape[1] + q2_train_vec.shape[1] + Xtrain.shape[1])\n",
    "X_test = hstack((q1_test_vec, q2_test_vec, np.array(Xtest)))\n",
    "assert(X_test.shape[1] == q1_test_vec.shape[1] + q2_test_vec.shape[1] + Xtest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SGDClassifier(penalty='l2', loss='log', random_state=42, n_jobs=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'alpha': np.logspace(-6, 10, 50)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=estimator,\n",
    "                    param_grid=params,\n",
    "                    scoring={'roc_auc', 'balanced_accuracy', 'neg_log_loss'},\n",
    "                    refit='neg_log_loss', # Because we are using multiple evaluation metrics\n",
    "                    cv=10,\n",
    "                    return_train_score=True,\n",
    "                    verbose=2,\n",
    "                    n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  21 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=10)]: Done 142 tasks      | elapsed:   59.6s\n",
      "[Parallel(n_jobs=10)]: Done 345 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=10)]: Done 500 out of 500 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=10, penalty='l2',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=10,\n",
       "       param_grid={'alpha': array([1.00000e-06, 2.12095e-06, 4.49843e-06, 9.54095e-06, 2.02359e-05,\n",
       "       4.29193e-05, 9.10298e-05, 1.93070e-04, 4.09492e-04, 8.68511e-04,\n",
       "       1.84207e-03, 3.90694e-03, 8.28643e-03, 1.75751e-02, 3.72759e-02,\n",
       "       7.90604e-02, 1.67683e-01, 3.55648e-01, 7.54312e-01, 1.59... 1.09854e+08, 2.32995e+08,\n",
       "       4.94171e+08, 1.04811e+09, 2.22300e+09, 4.71487e+09, 1.00000e+10])},\n",
       "       pre_dispatch='2*n_jobs', refit='neg_log_loss',\n",
       "       return_train_score=True,\n",
       "       scoring={'roc_auc', 'neg_log_loss', 'balanced_accuracy'}, verbose=2)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_alphas = get_summary_grid(grid).sort_values('test_neg_log_loss', ascending=False).alpha.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For values of alpha =  0.07906043210907686 The log loss is: 0.40938657887021995\n",
      "For values of alpha =  0.16768329368110066 The log loss is: 0.4107767631169659\n",
      "For values of alpha =  0.03727593720314938 The log loss is: 0.4151317154424956\n",
      "For values of alpha =  0.35564803062231287 The log loss is: 0.4172341712367717\n",
      "For values of alpha =  0.7543120063354607 The log loss is: 0.42798150084206454\n",
      "For values of alpha =  0.017575106248547894 The log loss is: 0.4328488141771995\n",
      "For values of alpha =  1.5998587196060574 The log loss is: 0.441921111271788\n",
      "For values of alpha =  3.393221771895323 The log loss is: 0.4571471236919364\n",
      "For values of alpha =  7.196856730011514 The log loss is: 0.47196286694829365\n",
      "For values of alpha =  15.264179671752302 The log loss is: 0.4870777622529951\n"
     ]
    }
   ],
   "source": [
    "alpha = good_alphas\n",
    "log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42, n_jobs=10, verbose=0)\n",
    "    clf.fit(X_train, ytrain)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=10)\n",
    "    sig_clf.fit(X_train, ytrain)\n",
    "    predict_y = sig_clf.predict_proba(X_test)\n",
    "    log_error_array.append(log_loss(ytest, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(ytest, predict_y, labels=clf.classes_, eps=1e-15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For values of penalty =  l1 The log loss is: 0.6585360623131012\n",
      "For values of penalty =  l2 The log loss is: 0.40938657887021995\n"
     ]
    }
   ],
   "source": [
    "log_error_array=[]\n",
    "for l in ['l1', 'l2']:\n",
    "    clf = SGDClassifier(alpha=0.07906043210907686, penalty=l, loss='log', random_state=42, n_jobs=10, verbose=0)\n",
    "    clf.fit(X_train, ytrain)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=10)\n",
    "    sig_clf.fit(X_train, ytrain)\n",
    "    predict_y = sig_clf.predict_proba(X_test)\n",
    "    log_error_array.append(log_loss(ytest, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "    print('For values of penalty = ', l, \"The log loss is:\",log_loss(ytest, predict_y, labels=clf.classes_, eps=1e-15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVC with SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For values of alpha =  0.07906043210907686 The log loss is: 0.4187434911781894\n",
      "For values of alpha =  0.16768329368110066 The log loss is: 0.41501052996812443\n",
      "For values of alpha =  0.03727593720314938 The log loss is: 0.43035992421519814\n",
      "For values of alpha =  0.35564803062231287 The log loss is: 0.4154973530006115\n",
      "For values of alpha =  0.7543120063354607 The log loss is: 0.4192151082070379\n",
      "For values of alpha =  0.017575106248547894 The log loss is: 0.4519119446375938\n",
      "For values of alpha =  1.5998587196060574 The log loss is: 0.42635427124384584\n",
      "For values of alpha =  3.393221771895323 The log loss is: 0.4378892370608103\n",
      "For values of alpha =  7.196856730011514 The log loss is: 0.4565228248487436\n",
      "For values of alpha =  15.264179671752302 The log loss is: 0.49261554104751976\n"
     ]
    }
   ],
   "source": [
    "alpha = good_alphas\n",
    "log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='hinge', random_state=42, n_jobs=10, verbose=0)\n",
    "    clf.fit(X_train, ytrain)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=10)\n",
    "    sig_clf.fit(X_train, ytrain)\n",
    "    predict_y = sig_clf.predict_proba(X_test)\n",
    "    log_error_array.append(log_loss(ytest, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(ytest, predict_y, labels=clf.classes_, eps=1e-15))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
