{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect('dataset/Cleaned.db') as conn:\n",
    "    train = pd.read_sql_query('SELECT * FROM train_with_leaks', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train.is_duplicate\n",
    "y_true = list(map(int, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(train, y_true, stratify=y_true, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyemd import emd\n",
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('/home/paperspace/w2v/GoogleNews-vectors-negative300.bin',\n",
    "                                         binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2vec(sentence, model, method='tfidf', **kwargs):\n",
    "    \"\"\"\n",
    "    Generic function to convert a sentence to a vector using\n",
    "    avg or TFIDF vecorization.\n",
    "    \n",
    "    :param sentence: Sentence to be converted.\n",
    "    :param model: The word2vec model\n",
    "    \"\"\"\n",
    "    \n",
    "    ##### It is recommended to pass seperate stopwords #####\n",
    "    stopwords = kwargs.get('stopwords')\n",
    "    if stopwords is None:\n",
    "        from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "        stopwords = ENGLISH_STOP_WORDS\n",
    "    \n",
    "    ##### It is recommended to pass seperate tokenizers #####\n",
    "    tokenizer = kwargs.get('tokenizer')\n",
    "    if tokenizer is None:\n",
    "        from nltk.tokenize import RegexpTokenizer\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "    words = tokenizer.tokenize(sentence) # Tokenize the words\n",
    "    words = {each for each in words if each not in stopwords} # Remove all the stopwords\n",
    "    \n",
    "    V = []\n",
    "    \n",
    "    for word in words: # Process over all the words in the sentence\n",
    "        if model.__contains__(word):\n",
    "            V.append(model[word])\n",
    "    V = np.array(V)\n",
    "    \n",
    "    # If no words were present in the model\n",
    "    # or blank sentence was passed, return a\n",
    "    # word vector with all 0's\n",
    "    if V.shape[0] == 0:\n",
    "        # If model returns word2vec of different size\n",
    "        # Default value is taken 300\n",
    "        custom_shape = kwargs.get('shape', 300)\n",
    "        return np.zeros(custom_shape)\n",
    "    \n",
    "    # If there is atleast one word in the sentence that\n",
    "    # was vectoried properly\n",
    "    \n",
    "    if method.lower() == 'avg':\n",
    "        V = V.sum(axis=0)\n",
    "        return V / np.sqrt((V ** 2).sum())\n",
    "    \n",
    "    elif method.lower() == 'tfidf':\n",
    "        tfidf_model = kwargs.get('tfidf_model') # Load the tfidf model\n",
    "        if tfidf_model: # If model loaded sucessfully\n",
    "            tfidf_vec = tfidf_model.transform([sentence]) # get TFIDF for the sentence\n",
    "            indx = tfidf_model.vocabulary_.get(word, -1)\n",
    "            tfidfs = []\n",
    "            for word in words:\n",
    "                if model.__contains__(word):\n",
    "                    if indx != -1:\n",
    "                        tfidfs.append(tfidf_vec[0, indx])\n",
    "                    else:\n",
    "                        tfidfs.append(0.0)\n",
    "            tfidfs = np.array(tfidfs)\n",
    "            denominator = tfidfs.sum()\n",
    "            if denominator == 0.0: # No word is representred in tfidf and w2v both\n",
    "                # Better than skipping that sentence\n",
    "                denominator = tfidf_model.idf_.min() * 0.01\n",
    "            numerator = V * tfidfs.reshape(V.shape[0], 1)\n",
    "            numerator = numerator.sum(axis=0)\n",
    "            return numerator / denominator\n",
    "        else:\n",
    "            raise ValueError('No tfidf model is present')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.fit(Xtrain.question1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1_vectors_train = np.zeros((Xtrain.shape[0], 300))\n",
    "for i, q in tqdm(enumerate(Xtrain.question1.values), total=283002):\n",
    "    question1_vectors_train[i, :] = sent2vec(q, model=model, tfidf_model=tfidf,\n",
    "                                       tokenizer=tokenizer, stopwords=ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1_vectors_test = np.zeros((Xtest.shape[0], 300))\n",
    "for i, q in tqdm(enumerate(Xtest.question1.values), total=121287):\n",
    "    question1_vectors_test[i, :] = sent2vec(q, model=model, tfidf_model=tfidf,\n",
    "                                       tokenizer=tokenizer, stopwords=ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.fit(Xtrain.question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question2_vectors_train = np.zeros((Xtrain.shape[0], 300))\n",
    "for i, q in tqdm(enumerate(Xtrain.question2.values), total=283002):\n",
    "    question2_vectors_train[i, :] = sent2vec(q, model=model, tfidf_model=tfidf,\n",
    "                                       tokenizer=tokenizer, stopwords=ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question2_vectors_test = np.zeros((Xtest.shape[0], 300))\n",
    "for i, q in tqdm(enumerate(Xtest.question2.values), total=121287):\n",
    "    question2_vectors_test[i, :] = sent2vec(q, model=model, tfidf_model=tfidf,\n",
    "                                       tokenizer=tokenizer, stopwords=ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1_vectors_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question2_vectors_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.drop([\n",
    "    'id',\n",
    "    'question1',\n",
    "    'question2',\n",
    "    'is_duplicate'\n",
    "], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest.drop([\n",
    "    'id',\n",
    "    'question1',\n",
    "    'question2',\n",
    "    'is_duplicate'\n",
    "], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.hstack((question1_vectors_train, question2_vectors_train, np.array(Xtrain)))\n",
    "X_test = np.hstack((question1_vectors_test, question2_vectors_test, np.array(Xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eval_metric'] = 'logloss'\n",
    "params['eta'] = 0.1\n",
    "params['max_depth'] = 5\n",
    "params['silent'] = 1\n",
    "params['subsample'] = 1\n",
    "params['colsample_bytree'] = 0.3\n",
    "params['reg_alpha'] = 100\n",
    "params['reg_lambda'] = 100\n",
    "\n",
    "d_train = xgb.DMatrix(X_train, label=ytrain)\n",
    "d_test = xgb.DMatrix(X_test, label=ytest)\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_test, 'valid')]\n",
    "\n",
    "clf = xgb.train(params, d_train, 400, watchlist, early_stopping_rounds=20, verbose_eval=1)\n",
    "predict_y = clf.predict(d_test)\n",
    "print('Test Log-Loss: ', log_loss(ytest, predict_y, eps=1e-15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOGLOSS**: 0.3204"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see that there is almost 0.03 improvement with this Leaky feature. But I guess the model is still slightly overfitting but how much it affects the leaderboard, that's the bigger question"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
